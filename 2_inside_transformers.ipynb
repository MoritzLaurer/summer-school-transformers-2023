{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "493701d6e621496c8d03f5d20b5aee56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23f34d72016d46a6b0600e2a4c844457",
              "IPY_MODEL_d52b6083126e4e2985e56763c566e685",
              "IPY_MODEL_050bba1cc4114af887c4d36f84201ae2"
            ],
            "layout": "IPY_MODEL_cc0b8c271f7c40dfb620d5527bfdfb8c"
          }
        },
        "23f34d72016d46a6b0600e2a4c844457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20ba04dad7bc4b61a26ade8bf8c8bb70",
            "placeholder": "​",
            "style": "IPY_MODEL_3a5b891c42f84dce90ab697f01e041ed",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "d52b6083126e4e2985e56763c566e685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd425ff2e91745eea6ba14e6f4a00fc7",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2bd378e36f904236bae80c898f843743",
            "value": 48
          }
        },
        "050bba1cc4114af887c4d36f84201ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_917b8d66a301472eadcc8e32034f52ab",
            "placeholder": "​",
            "style": "IPY_MODEL_cccbdfa62ee3453893d248a981265aed",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.27kB/s]"
          }
        },
        "cc0b8c271f7c40dfb620d5527bfdfb8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20ba04dad7bc4b61a26ade8bf8c8bb70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a5b891c42f84dce90ab697f01e041ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd425ff2e91745eea6ba14e6f4a00fc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bd378e36f904236bae80c898f843743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "917b8d66a301472eadcc8e32034f52ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cccbdfa62ee3453893d248a981265aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37960b4f496c42398d4c2c58dbced904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eac347e3289e42489a14cf99b100cea6",
              "IPY_MODEL_5d3d8e0601b64562b74861173deb8529",
              "IPY_MODEL_76aab60cba404322b9d58c553475174a"
            ],
            "layout": "IPY_MODEL_4a6cdad53d49415187b07a41aa2a03e9"
          }
        },
        "eac347e3289e42489a14cf99b100cea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_729b1dc2e6ba4d56bb6c83ff29b16dd1",
            "placeholder": "​",
            "style": "IPY_MODEL_1c8941e6ba964a939a709f9086d0fe59",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "5d3d8e0601b64562b74861173deb8529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_871cc69057dd44a79252d3aa316bd3fd",
            "max": 629,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93c786aeb64049b8ae29eb386a481a72",
            "value": 629
          }
        },
        "76aab60cba404322b9d58c553475174a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb8a1527bd434f86a311743831eaef4e",
            "placeholder": "​",
            "style": "IPY_MODEL_c7da246eec7f4ba18c45ed5570ac15c4",
            "value": " 629/629 [00:00&lt;00:00, 26.0kB/s]"
          }
        },
        "4a6cdad53d49415187b07a41aa2a03e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "729b1dc2e6ba4d56bb6c83ff29b16dd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c8941e6ba964a939a709f9086d0fe59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "871cc69057dd44a79252d3aa316bd3fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93c786aeb64049b8ae29eb386a481a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb8a1527bd434f86a311743831eaef4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7da246eec7f4ba18c45ed5570ac15c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17ea781cca644f07acbe247b5a6ff859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f657402f0bf54a6bbf7331989720c27c",
              "IPY_MODEL_3264365492ef40e3aacf05d4f9ff7205",
              "IPY_MODEL_48c9d15234234b1e84b5fa4984794e61"
            ],
            "layout": "IPY_MODEL_aea754386ff7496d8662c307236c100e"
          }
        },
        "f657402f0bf54a6bbf7331989720c27c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_296ae03293e04b36ab4255c928886724",
            "placeholder": "​",
            "style": "IPY_MODEL_5080f63bd96e464292a7c0b1798a6c21",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "3264365492ef40e3aacf05d4f9ff7205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec6a3e682e7d41e78304b413a70bad95",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26b4b1a676bd4c53aab48bc0b9808a22",
            "value": 231508
          }
        },
        "48c9d15234234b1e84b5fa4984794e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c02e87b65f64eec887d85e2856763d7",
            "placeholder": "​",
            "style": "IPY_MODEL_44df7463889e4b9e8fd3a96c1c215bbb",
            "value": " 232k/232k [00:00&lt;00:00, 4.34MB/s]"
          }
        },
        "aea754386ff7496d8662c307236c100e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "296ae03293e04b36ab4255c928886724": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5080f63bd96e464292a7c0b1798a6c21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec6a3e682e7d41e78304b413a70bad95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26b4b1a676bd4c53aab48bc0b9808a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c02e87b65f64eec887d85e2856763d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44df7463889e4b9e8fd3a96c1c215bbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4df2e13ae984048b6dba831090b0104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40989a608e9a4230887d87d5c42d0072",
              "IPY_MODEL_1fff6d8e2e934e289ed66a6c5bbdd1d6",
              "IPY_MODEL_e9994f886d59401cbf64809557224b7f"
            ],
            "layout": "IPY_MODEL_5f94bf3cb0324c778e82ccbbbb6829d1"
          }
        },
        "40989a608e9a4230887d87d5c42d0072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bfbda13e55e402f8af774f477e6a7bd",
            "placeholder": "​",
            "style": "IPY_MODEL_2ff9f4b166934737aba42e6a9056a647",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "1fff6d8e2e934e289ed66a6c5bbdd1d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e786d4b1001448c0b2fbf6f7b04efe4b",
            "max": 267832558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f14002b415e84f6a872430a99ed4848b",
            "value": 267832558
          }
        },
        "e9994f886d59401cbf64809557224b7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3372b3f169ad45aaa5c06249c54d49dc",
            "placeholder": "​",
            "style": "IPY_MODEL_bd6d4c59d8e54f14b86562d4463d25ca",
            "value": " 268M/268M [00:23&lt;00:00, 10.7MB/s]"
          }
        },
        "5f94bf3cb0324c778e82ccbbbb6829d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bfbda13e55e402f8af774f477e6a7bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ff9f4b166934737aba42e6a9056a647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e786d4b1001448c0b2fbf6f7b04efe4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f14002b415e84f6a872430a99ed4848b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3372b3f169ad45aaa5c06249c54d49dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd6d4c59d8e54f14b86562d4463d25ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYLjU9bVQiI9"
      },
      "source": [
        "#  🤖 A pratical look inside of Transformers 🤖\n",
        "\n",
        "📅 _Data Science Summer School 2023, 22.08.2023_\n",
        "\n",
        "👨‍🏫 By [Moritz Laurer](https://www.linkedin.com/in/moritz-laurer/).\n",
        "For questions, reach out to: m.laurer@vu.nl\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "</a><a href=\"https://github.com/MoritzLaurer/summer-school-transformers-2023/blob/main/2_inside_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "gOzoalCdFoQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformers' main components"
      ],
      "metadata": {
        "id": "0-JnK7Zkhmj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hugging Face Transformers has two main components:**\n"
      ],
      "metadata": {
        "id": "u2v9wkhQhuf4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHkp89twf4Zq"
      },
      "source": [
        "\n",
        "1. The **tokenizer** prepares the text in a clean format, which the model understands.\n",
        "    - A token is a word or a sub-word unit. In BERT's vocabulary, the word \"good\" is one token and the word \"darwinism\" is two tokens  (\"darwin\" and \"ism\")\n",
        "    - The tokenizer transforms words into token-ids. With these token-ids, BERT can link words to any token it has already learned during pre-training.\n",
        "\n",
        "2. The **model** processes the tokenizer's ouput and returns a prediction, e.g. which class an input text belongs to.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Independently of the type of model (classification, summarisation, translation, etc.), these two components are almost the same."
      ],
      "metadata": {
        "id": "A4tmhG0piJ0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers~=4.31.0  # The Transformers library from Hugging Face"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNjndqEeVP5h",
        "outputId": "7a06e228-2204-4597-d18d-d3194d4cc171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers~=4.31.0\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers~=4.31.0) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers~=4.31.0)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.31.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.31.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.31.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.31.0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers~=4.31.0) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers~=4.31.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers~=4.31.0)\n",
            "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers~=4.31.0) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers~=4.31.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers~=4.31.0) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers~=4.31.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers~=4.31.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers~=4.31.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers~=4.31.0) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models like BERT (encoders)"
      ],
      "metadata": {
        "id": "j0axlrhOhTGu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hykl2GkBhq5F"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HneEleBYh_tY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "493701d6e621496c8d03f5d20b5aee56",
            "23f34d72016d46a6b0600e2a4c844457",
            "d52b6083126e4e2985e56763c566e685",
            "050bba1cc4114af887c4d36f84201ae2",
            "cc0b8c271f7c40dfb620d5527bfdfb8c",
            "20ba04dad7bc4b61a26ade8bf8c8bb70",
            "3a5b891c42f84dce90ab697f01e041ed",
            "dd425ff2e91745eea6ba14e6f4a00fc7",
            "2bd378e36f904236bae80c898f843743",
            "917b8d66a301472eadcc8e32034f52ab",
            "cccbdfa62ee3453893d248a981265aed",
            "37960b4f496c42398d4c2c58dbced904",
            "eac347e3289e42489a14cf99b100cea6",
            "5d3d8e0601b64562b74861173deb8529",
            "76aab60cba404322b9d58c553475174a",
            "4a6cdad53d49415187b07a41aa2a03e9",
            "729b1dc2e6ba4d56bb6c83ff29b16dd1",
            "1c8941e6ba964a939a709f9086d0fe59",
            "871cc69057dd44a79252d3aa316bd3fd",
            "93c786aeb64049b8ae29eb386a481a72",
            "bb8a1527bd434f86a311743831eaef4e",
            "c7da246eec7f4ba18c45ed5570ac15c4",
            "17ea781cca644f07acbe247b5a6ff859",
            "f657402f0bf54a6bbf7331989720c27c",
            "3264365492ef40e3aacf05d4f9ff7205",
            "48c9d15234234b1e84b5fa4984794e61",
            "aea754386ff7496d8662c307236c100e",
            "296ae03293e04b36ab4255c928886724",
            "5080f63bd96e464292a7c0b1798a6c21",
            "ec6a3e682e7d41e78304b413a70bad95",
            "26b4b1a676bd4c53aab48bc0b9808a22",
            "9c02e87b65f64eec887d85e2856763d7",
            "44df7463889e4b9e8fd3a96c1c215bbb",
            "e4df2e13ae984048b6dba831090b0104",
            "40989a608e9a4230887d87d5c42d0072",
            "1fff6d8e2e934e289ed66a6c5bbdd1d6",
            "e9994f886d59401cbf64809557224b7f",
            "5f94bf3cb0324c778e82ccbbbb6829d1",
            "4bfbda13e55e402f8af774f477e6a7bd",
            "2ff9f4b166934737aba42e6a9056a647",
            "e786d4b1001448c0b2fbf6f7b04efe4b",
            "f14002b415e84f6a872430a99ed4848b",
            "3372b3f169ad45aaa5c06249c54d49dc",
            "bd6d4c59d8e54f14b86562d4463d25ca"
          ]
        },
        "outputId": "7b8bd2a9-f1f1-4aad-da99-c3bb16601d76"
      },
      "source": [
        "# load any classification model from the HuggingFace model hub\n",
        "# See here: https://huggingface.co/models?pipeline_tag=text-classification\n",
        "\n",
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "\n",
        "# instantiate the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# instantiate the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "493701d6e621496c8d03f5d20b5aee56"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37960b4f496c42398d4c2c58dbced904"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17ea781cca644f07acbe247b5a6ff859"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4df2e13ae984048b6dba831090b0104"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zluWT2EpHd64"
      },
      "source": [
        "### Tokenization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLKD6HULf4hX",
        "outputId": "0be8f1c9-bf7d-4931-e181-735185056f41"
      },
      "source": [
        "### 1. Tokenization\n",
        "# Tokenizer documentation: https://huggingface.co/transformers/main_classes/tokenizer.html\n",
        "\n",
        "text = 'I believe that the EU is trustworthy.'\n",
        "print(f\"Input text: '{text}'\\n\")\n",
        "\n",
        "input_ids = tokenizer(text, truncation=True, return_tensors=\"pt\")[\"input_ids\"]\n",
        "print(f\"\"\"The tokenizer splits the text string into separate tokens. A token is either an entire word,\n",
        "or a 'sub-word unit' in case of rare words (or punctuation).\n",
        "The word 'trustworthy', for example is split into two tokens: {tokenizer.tokenize(\"Trustworthy\")}.\n",
        "The main advantage of these sub-word units is that rare words cannot be out-of-vocabulary (an issue of other text-as-data approaches).\n",
        "Transformer models typically have a vocabulary of around 30.000 - 250.000 tokens, learned from the training data.\n",
        "Here is e.g. the vocabulary of DistilBERT: https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt\\n\"\"\")\n",
        "\n",
        "print(f\"The input text is split into the following tokens:\\n{tokenizer.tokenize(text)}.\")\n",
        "print(\"The tokenizer then maps each token to the corresponding token ID in the model's vocabulary:\")\n",
        "print(input_ids[0].tolist()[1:-1])\n",
        "print(\"Transformer models only understand these token IDs.\\n\")\n",
        "\n",
        "print(\"\"\"In addition, the tokenizer adds two special tokens:\n",
        " First, the [CLS] (classification) token is always added at the beginning.\n",
        "        While individual tokens represent individual (sub)words, the [CLS] token represents the entire text.\n",
        "        The [CLS] token \"is  used  as  the  aggregate sequence representation for classification tasks\" (Devlin et al. 2019: 4). Details: https://arxiv.org/pdf/1810.04805.pdf\n",
        " Second, the [SEP] token separates two texts. It is useful for tasks which require two text inputs, for example Questions & Answer tasks.\n",
        "        (It is not relevant in our case)\n",
        "\\n\"\"\")\n",
        "\n",
        "print(\"\"\"The final input for a BERT transformer model therefore looks like this:\"\"\")\n",
        "token_strings = tokenizer.convert_ids_to_tokens(ids=input_ids[0])\n",
        "#token_strings = tokenizer.tokenize(text)\n",
        "for token_id, token_string in zip(input_ids[0].tolist(), token_strings):\n",
        "  print(token_id, \" == \", token_string)\n",
        "\n",
        "\n",
        "# entire vocabulary: tokenizer.pretrained_vocab_files_map[\"vocab_file\"][\"distilbert-base-uncased\"]\n",
        "# https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input text: 'I believe that the EU is trustworthy.'\n",
            "\n",
            "The tokenizer splits the text string into separate tokens. A token is either an entire word,\n",
            "or a 'sub-word unit' in case of rare words (or punctuation).\n",
            "The word 'trustworthy', for example is split into two tokens: ['trust', '##worthy'].\n",
            "The main advantage of these sub-word units is that rare words cannot be out-of-vocabulary (an issue of other text-as-data approaches).\n",
            "Transformer models typically have a vocabulary of around 30.000 - 250.000 tokens, learned from the training data. \n",
            "Here is e.g. the vocabulary of DistilBERT: https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt\n",
            "\n",
            "The input text is split into the following tokens:\n",
            "['i', 'believe', 'that', 'the', 'eu', 'is', 'trust', '##worthy', '.'].\n",
            "The tokenizer then maps each token to the corresponding token ID in the model's vocabulary:\n",
            "[1045, 2903, 2008, 1996, 7327, 2003, 3404, 13966, 1012]\n",
            "Transformer models only understand these token IDs.\n",
            "\n",
            "In addition, the tokenizer adds two special tokens:\n",
            " First, the [CLS] (classification) token is always added at the beginning. \n",
            "        While individual tokens represent individual (sub)words, the [CLS] token represents the entire text. \n",
            "        The [CLS] token \"is  used  as  the  aggregate sequence representation for classification tasks\" (Devlin et al. 2019: 4). Details: https://arxiv.org/pdf/1810.04805.pdf\n",
            " Second, the [SEP] token separates two texts. It is useful for tasks which require two text inputs, for example Questions & Answer tasks.\n",
            "        (It is not relevant in our case)\n",
            "\n",
            "\n",
            "The final input for a BERT transformer model therefore looks like this:\n",
            "101  ==  [CLS]\n",
            "1045  ==  i\n",
            "2903  ==  believe\n",
            "2008  ==  that\n",
            "1996  ==  the\n",
            "7327  ==  eu\n",
            "2003  ==  is\n",
            "3404  ==  trust\n",
            "13966  ==  ##worthy\n",
            "1012  ==  .\n",
            "102  ==  [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokens (words) flowing through the neural network"
      ],
      "metadata": {
        "id": "rw7qQhjGcZ8d"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z8vNYtliIaJ",
        "outputId": "e3fd40b1-887e-4195-d332-05d4ac9ff68d"
      },
      "source": [
        "### Processing the input with the model\n",
        "# Model class documentation: https://huggingface.co/transformers/main_classes/model.html\n",
        "# Documentation for DistilBERT specifically: https://huggingface.co/transformers/model_doc/distilbert.html\n",
        "\n",
        "print(f\"\"\"\\nAfter the preprocessing by the tokenizer, the model then feeds the sequence of tokens through the neural network.\n",
        "Each token is represented by a vector of 768 numbers (a 768 dimensional tensor).\n",
        "The tensor for the token \"trust\" looks for example like this before being fed into the first neural network layer\n",
        "(only 100 numbers are displayed):\\n\"\"\")\n",
        "print(model.distilbert.embeddings.word_embeddings(input_ids[0][7])[:100], \"\\n\")\n",
        "\n",
        "print(f\"\"\"The tensors for each token are then fed through and transformed by between 6-24~ neural network layers.\\n\"\"\")\n",
        "\n",
        "output = model(input_ids, output_hidden_states=True, output_attentions=False, return_dict=True)\n",
        "print(\"Same word after the first layer:\\n\\n\", output.hidden_states[1][0][7][:100], \"\\n\")  # same word embedding after the first attention layer\n",
        "print(\"Same word after the second layer:\\n\\n\", output.hidden_states[2][0][7][:100], \"\\n\")  # same word embedding after the second attention layer\n",
        "#print(\"Same word after the third layer:\\n\", output.hidden_states[3][0][7][:100], \"\\n\")  # same word embedding after the third attention layer\n",
        "print(\"\\n ... etc ...\\n\")\n",
        "\n",
        "print(f'The final output is a a contextualised representation of the sequence: \"{text}\"')\n",
        "#output.hidden_states[6][0][0][:100]  # final CLS token"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After the preprocessing by the tokenizer, the model then feeds the sequence of tokens through the neural network.\n",
            "Each token is represented by a vector of 768 numbers (a 768 dimensional tensor).\n",
            "The tensor for the token \"trust\" looks for example like this before being fed into the first neural network layer \n",
            "(only 100 numbers are displayed):\n",
            "\n",
            "tensor([-0.0263, -0.0292, -0.0186,  0.0289,  0.0225,  0.0005, -0.0649,  0.0440,\n",
            "         0.0201,  0.0052, -0.0857, -0.0903, -0.0182, -0.0214, -0.0514, -0.0074,\n",
            "        -0.0361, -0.0715,  0.0125, -0.0320, -0.0118, -0.0252, -0.0431, -0.0383,\n",
            "         0.0073,  0.0188,  0.0049, -0.0829, -0.0150, -0.0313, -0.0517,  0.0518,\n",
            "         0.0099,  0.0418, -0.0135, -0.0256, -0.0432, -0.0029, -0.0191,  0.0006,\n",
            "         0.0023,  0.0052, -0.0705, -0.0053, -0.0237, -0.0131,  0.0082, -0.0160,\n",
            "        -0.0512,  0.0171,  0.0104, -0.0164, -0.0536, -0.0759, -0.0407, -0.0006,\n",
            "        -0.0331, -0.0792,  0.0354, -0.0010, -0.0222, -0.0015, -0.0628, -0.0206,\n",
            "        -0.1149, -0.0215, -0.0275, -0.0074, -0.0037,  0.0314, -0.0694, -0.0056,\n",
            "        -0.0402, -0.0959, -0.1495, -0.0860, -0.0756, -0.0939, -0.0162,  0.0127,\n",
            "        -0.0333, -0.0174, -0.0606, -0.0488,  0.0328, -0.0653, -0.0148,  0.0429,\n",
            "        -0.0382,  0.0021,  0.0154, -0.0832, -0.0312,  0.0751, -0.0100, -0.0326,\n",
            "         0.0089, -0.0080, -0.0745, -0.0516], grad_fn=<SliceBackward0>) \n",
            "\n",
            "The tensors for each token are then fed through and transformed by between 6-24~ neural network layers.\n",
            "\n",
            "Same word after the first layer:\n",
            "\n",
            " tensor([ 1.0197, -0.5487,  0.3499,  0.4607,  0.8391, -0.1893, -1.2744,  0.4050,\n",
            "         0.5758,  0.5190, -1.3808, -0.4710,  0.1655, -0.9737, -0.9132,  0.0945,\n",
            "         0.1522, -0.7325,  0.4531, -0.1877, -0.0658,  0.5347, -0.2890,  0.2111,\n",
            "         0.0095,  1.8999,  0.3661, -0.1923, -0.1967,  0.0840, -0.9437,  0.6535,\n",
            "         0.8659,  1.1503,  0.5523, -0.0571, -0.5224,  0.5320,  0.4575,  0.0705,\n",
            "         0.5444,  0.6075, -0.5054,  0.6493, -0.7816, -0.1386,  0.9620,  0.1940,\n",
            "         0.2520,  0.2409,  0.3830, -0.0106, -0.9761, -0.4375, -0.1450,  0.3104,\n",
            "        -0.4289, -0.2048,  0.7036,  0.0452,  0.3296,  0.4499,  0.4429, -0.7283,\n",
            "        -2.3567,  0.3876, -0.9062,  0.0851, -0.0852,  0.0829, -0.8152, -0.3009,\n",
            "        -0.6328, -1.0584, -2.2323, -0.9247, -1.3073, -0.2668,  0.3371,  0.0062,\n",
            "         0.2274, -0.0837, -1.3364, -0.1008,  0.2650, -1.4553,  0.6272,  0.5761,\n",
            "        -0.1431, -0.0612, -0.0905, -0.8610, -0.4050,  1.5188,  0.6204, -0.2890,\n",
            "         0.3655,  0.1397, -1.0399, -0.5957], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Same word after the second layer:\n",
            "\n",
            " tensor([ 8.6304e-01, -8.6820e-01,  7.8730e-01, -2.2138e-01,  1.2101e+00,\n",
            "         3.8670e-01, -1.0896e+00,  8.7422e-02,  4.7191e-01,  3.4434e-02,\n",
            "        -1.0020e+00,  6.2982e-01, -1.2089e-01, -5.2946e-01, -1.1913e+00,\n",
            "        -4.6408e-01,  1.9621e-02, -7.6431e-01, -4.3572e-01, -2.6467e-01,\n",
            "         1.8397e-01,  1.6879e-01,  3.4552e-02,  3.8005e-01, -1.0561e+00,\n",
            "         1.5122e+00,  8.2248e-01,  1.1769e-02,  6.4608e-02,  7.2765e-01,\n",
            "        -6.4231e-01, -1.5865e-02,  3.4215e-01,  1.7413e+00,  4.9454e-01,\n",
            "        -5.1311e-01, -3.9811e-01,  3.1635e-01,  9.2214e-01, -5.0008e-02,\n",
            "        -1.1514e-01,  6.3453e-01, -2.1228e-02,  5.0645e-01, -3.6516e-01,\n",
            "         9.9460e-02,  5.1015e-01, -2.4458e-01, -7.1837e-02, -1.2050e-01,\n",
            "        -1.2111e-01, -5.2317e-01, -9.3992e-01, -3.8500e-01,  1.9844e-01,\n",
            "        -7.1985e-01, -1.7236e+00, -2.9698e-01,  5.4476e-01,  6.2087e-01,\n",
            "         1.1353e+00,  4.7976e-02,  7.7644e-02, -1.1994e+00, -1.6474e+00,\n",
            "        -8.3197e-02, -7.1110e-01,  4.4613e-01, -1.4741e-01, -1.5836e-02,\n",
            "         9.5763e-04, -1.7963e-01, -2.0893e-01, -8.2586e-01, -1.6915e+00,\n",
            "        -3.0478e-01, -7.3935e-01, -3.4275e-01,  7.6856e-01, -1.3046e-01,\n",
            "         6.7788e-01, -1.4471e-01, -1.2505e+00, -2.1345e-01, -2.3939e-01,\n",
            "        -1.3216e+00,  1.0545e+00, -1.3779e-01, -2.7386e-01,  3.0029e-01,\n",
            "        -6.4045e-01, -9.0891e-01,  1.5595e-01,  1.4556e+00,  4.6438e-01,\n",
            "        -8.5181e-02,  5.4725e-01,  3.0987e-01, -6.2029e-01, -6.2813e-01],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "\n",
            " ... etc ...\n",
            "\n",
            "The final output is a a contextualised representation of the sequence: \"I believe that the EU is trustworthy.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ey7iZ13DsoKa",
        "outputId": "69127a17-3372-4d22-8ddf-004848e76d2f"
      },
      "source": [
        "print(\"This is what the different model layers ('the architecture') look like:\\n\")\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is what the different model layers ('the architecture') look like:\n",
            "\n",
            "DistilBertForSequenceClassification(\n",
            "  (distilbert): DistilBertModel(\n",
            "    (embeddings): Embeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): Transformer(\n",
            "      (layer): ModuleList(\n",
            "        (0-5): 6 x TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (activation): GELUActivation()\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The final output"
      ],
      "metadata": {
        "id": "SNThz6Mdc6Ei"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1ecRDjcsh-Z",
        "outputId": "abcf26b8-fcc5-48fb-b6b4-2f9d18affa3c"
      },
      "source": [
        "print(f\"\"\"At the end, Transformer models always output so called 'logits',\\n one number for each class the model was trained to classify text into.\\n\n",
        "Our input text was: '{text}'\\n\n",
        "These logis represent the predicted probability for our binary sentiment classification task:\\n\\n{output[\"logits\"][0].tolist()}\\n\"\"\")\n",
        "\n",
        "print(\"Logits are not very interpretable, so they are then converted to percentages.\\nEach percentages represents the model's prediction, which class the input text belongs to.\\n\")\n",
        "probabilities = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
        "label_names = model.config.id2label.values()\n",
        "prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(probabilities, label_names)}\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At the end, Transformer models always output so called 'logits',\n",
            " one number for each class the model was trained to classify text into.\n",
            "\n",
            "Our input text was: 'I believe that the EU is trustworthy.'\n",
            "\n",
            "These logis represent the predicted probability for our binary sentiment classification task:\n",
            "\n",
            "[-3.50547456741333, 3.680955171585083]\n",
            "\n",
            "Logits are not very interpretable, so they are then converted to percentages.\n",
            "Each percentages represents the model's prediction, which class the input text belongs to.\n",
            "\n",
            "{'NEGATIVE': 0.1, 'POSITIVE': 99.9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_AJJsLQHq3l"
      },
      "source": [
        "### Everything put together\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZK019KRAxHm",
        "outputId": "61e143fd-0f4e-4868-b371-de4707ef881e"
      },
      "source": [
        "## In short, the code looks like this:\n",
        "\n",
        "# load the relevant functions from HuggingFace and PyTorch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Choose any classification model from the model hub\n",
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "\n",
        "# instantiate the tokenizer and the model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# tokenization\n",
        "text = 'I believe that the EU is trustworthy.'\n",
        "input = tokenizer(text, truncation=True, return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "# model prediction\n",
        "output = model(input, output_hidden_states=False, output_attentions=False, return_dict=True)\n",
        "probabilities = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
        "label_names = model.config.id2label.values()\n",
        "prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(probabilities, label_names)}\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'NEGATIVE': 0.1, 'POSITIVE': 99.9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrJNiO8HBX8v",
        "outputId": "1cebfffa-cb21-493e-baab-d4dcf4301830"
      },
      "source": [
        "## Or via the simplified pipeline:\n",
        "from transformers import pipeline\n",
        "pipe_classification = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\", top_k=2)\n",
        "text = 'I believe that the EU is trustworthy.'\n",
        "pipe_classification(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': 'POSITIVE', 'score': 0.9992438554763794},\n",
              "  {'label': 'NEGATIVE', 'score': 0.0007562137907370925}]]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generative models like GPT (decoders)"
      ],
      "metadata": {
        "id": "RCq3Nf6-z4LS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# https://huggingface.co/gpt2\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "\n",
        "prompt = \"Today I believe we can finally\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_length=30)\n",
        "\n",
        "outputs_decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "print(outputs_decoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4R3RIWJj0DBf",
        "outputId": "0652a3a6-fe61-4839-d606-83f16fe20ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Today I believe we can finally get to the point where we can make a difference in the lives of the people of the United States of America.\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# https://huggingface.co/gpt2\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "\n",
        "prompt = \"Today I believe we can finally\"\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# gpt2's vocabulary: https://huggingface.co/gpt2/raw/main/vocab.json\n",
        "\n",
        "outputs = model.generate(\n",
        "    input_ids, max_length=30,\n",
        "    output_scores=True, return_dict_in_generate=True,\n",
        "    output_attentions=False, do_sample=False\n",
        ")\n",
        "\n",
        "print(\"\\nThe output looks quite messy:\\n\")\n",
        "print(outputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_FR2ctZ0yvG",
        "outputId": "dd6a0888-ebb1-4708-9152-984d4a04e624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The output looks quite messy:\n",
            "\n",
            "GreedySearchDecoderOnlyOutput(sequences=tensor([[8888,  314, 1975,  356,  460, 3443,  651,  284,  262,  966,  810,  356,\n",
            "          460,  787,  257, 3580,  287,  262, 3160,  286,  262,  661,  286,  262,\n",
            "         1578, 1829,  286, 2253,   13,  198]]), scores=(tensor([[-148.6821, -149.2908, -156.0585,  ..., -162.4584, -158.8699,\n",
            "         -150.9391]]), tensor([[-115.6685, -116.1134, -120.9431,  ..., -121.5678, -122.0461,\n",
            "         -116.7151]]), tensor([[-102.9193, -102.8433, -106.7674,  ..., -109.7448, -110.1562,\n",
            "         -104.3626]]), tensor([[-113.0016, -111.4651, -116.1575,  ..., -115.7574, -119.9194,\n",
            "         -112.3750]]), tensor([[-85.0493, -86.2461, -92.9495,  ..., -96.9331, -97.5099, -88.6309]]), tensor([[-101.4949, -101.3607, -106.5000,  ..., -105.3603, -108.2615,\n",
            "         -102.6192]]), tensor([[-144.4079, -143.1993, -147.8557,  ..., -153.8577, -149.4084,\n",
            "         -145.1063]]), tensor([[-142.9678, -142.7155, -149.5450,  ..., -154.4601, -153.3980,\n",
            "         -144.9618]]), tensor([[-107.0143, -106.5295, -112.6670,  ..., -110.6300, -114.1609,\n",
            "         -108.2180]]), tensor([[-136.4494, -134.5512, -138.7625,  ..., -143.6068, -142.1176,\n",
            "         -135.7249]]), tensor([[-109.8607, -109.8172, -119.3194,  ..., -124.9031, -125.0524,\n",
            "         -113.8864]]), tensor([[-106.7517, -105.5090, -110.3002,  ..., -111.1601, -112.8438,\n",
            "         -107.1498]]), tensor([[-130.9350, -128.7390, -133.6040,  ..., -132.8402, -135.4676,\n",
            "         -129.3461]]), tensor([[-39.1257, -36.0714, -45.9913,  ..., -49.6895, -46.9359, -41.5144]]), tensor([[-123.4334, -122.4138, -127.8127,  ..., -124.1029, -129.7923,\n",
            "         -123.4686]]), tensor([[-125.3868, -123.8290, -128.6104,  ..., -124.4080, -129.1839,\n",
            "         -124.1066]]), tensor([[-110.4702, -109.6479, -119.3324,  ..., -122.6705, -120.5585,\n",
            "         -114.1835]]), tensor([[ -97.1338,  -96.7021, -100.0708,  ..., -101.8569, -104.7260,\n",
            "          -97.4858]]), tensor([[-116.5378, -115.0052, -118.4467,  ..., -117.5226, -121.5477,\n",
            "         -115.1521]]), tensor([[-223.1000, -221.9221, -225.2949,  ..., -236.5790, -240.2267,\n",
            "         -223.4587]]), tensor([[-82.4272, -81.1039, -90.4330,  ..., -95.9789, -96.0215, -85.2337]]), tensor([[-178.7832, -180.3468, -182.6521,  ..., -186.7446, -193.9576,\n",
            "         -179.8750]]), tensor([[ -92.5517,  -92.2312, -100.1863,  ..., -108.7172, -106.8259,\n",
            "          -95.7613]]), tensor([[-160.1643, -159.1199, -159.8176,  ..., -175.6871, -177.5045,\n",
            "         -151.5896]])), attentions=None, hidden_states=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GPT2's vocabulary is composed of 50257 tokens. Each has a 'word vector' composed of 768 numbers:\")\n",
        "print(model.transformer.wte)\n",
        "\n",
        "print(f\"\"\"\\nWe can look at GPT2's entire vocabulary here: https://huggingface.co/gpt2/raw/main/vocab.json\n",
        "\\nFor example, the token 'Love' is at position 18565.\n",
        "\\nWe can access it's word vector here (first 100 numbers):\\n\n",
        "{model.transformer.wte.weight[18565][:100]}\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIcWIkzx3wmC",
        "outputId": "322c7a7f-9a87-4005-cba3-e0138bf14db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2's vocabulary is composed of 50257 tokens. Each has a 'word vector' composed of 768 numbers:\n",
            "Embedding(50257, 768)\n",
            "\n",
            "We can look at GPT2's entire vocabulary here: https://huggingface.co/gpt2/raw/main/vocab.json\n",
            "\n",
            "For example, the token 'Love' is at position 18565.\n",
            "\n",
            "We can access it's word vector here (first 100 numbers):\n",
            "\n",
            "tensor([-0.0521,  0.0063,  0.0773,  0.1031, -0.0365, -0.0253, -0.2183,  0.0222,\n",
            "        -0.1285, -0.0917, -0.0771, -0.1728,  0.1625, -0.1056,  0.1838, -0.0049,\n",
            "         0.0246, -0.0203,  0.0717,  0.1154,  0.0384, -0.2783,  0.0206,  0.0678,\n",
            "        -0.1182, -0.0169,  0.0946, -0.1425,  0.1875, -0.0393,  0.1161, -0.4728,\n",
            "         0.1959,  0.0616, -0.1545,  0.0377, -0.3193,  0.1089,  0.0265, -0.0317,\n",
            "         0.1023, -0.0070,  0.0394,  0.0017,  0.1093,  0.1821,  0.1139, -0.0832,\n",
            "         0.0032, -0.0456, -0.0501, -0.0303, -0.0005, -0.2116, -0.0135, -0.2888,\n",
            "        -0.0223,  0.1179,  0.0222,  0.3011,  0.0113,  0.1022, -0.1399, -0.0165,\n",
            "         0.2658,  0.1221, -0.1152, -0.1597,  0.3961,  0.0925,  0.0124,  0.1865,\n",
            "        -0.1736,  0.1215,  0.0576, -0.0720,  0.1281,  0.0823, -0.0360,  0.0325,\n",
            "         0.2140,  0.1219, -0.0035,  0.2351,  0.0536, -0.0379, -0.1372,  0.2510,\n",
            "         0.0493,  0.1837, -0.1628,  0.0623,  0.0266, -0.0706,  0.2387,  0.0577,\n",
            "         0.0005, -0.1481, -0.1461, -0.0766], grad_fn=<SliceBackward0>)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"\"\"\n",
        "While the outputs produce by classifiers like BERT are probabilities of classes,\n",
        "the outputs produced by generators like GPT2 are probabilities of tokens.\n",
        "\\nThese probabilities of tokens are in the 'outputs' object returned by model.generate()\n",
        "\\nThe IDs of the most probably tokens are:\n",
        "{outputs.sequences}\n",
        "\\nThese token IDs can be mapped to actuall words/tokens in the vocabulary:\n",
        "{tokenizer.batch_decode(outputs.sequences, skip_special_tokens=True)}\\n\\n\n",
        "\n",
        "Our original prompt was:\\n'{prompt}'\n",
        "GPT2 then tries to predict the most probable next token. One token after the other.\n",
        "\n",
        "To calculate the first token, it makes a prediction over ALL of the 50257 tokens it knows.\n",
        "Each of the 50257 tokens receives a probability.\n",
        "First the first token, the probability distribution over its ENTIRE vocabulary looks like this:\n",
        "{outputs.scores[0][0]}\n",
        "\n",
        "The ID of the most probable *first* token is {torch.argmax(outputs.scores[0][0], dim=0)}\n",
        "The corresponding token is: {tokenizer.decode(torch.argmax(outputs.scores[0][0], dim=0))}\n",
        "\n",
        "The ID of the most probable *second* token is {torch.argmax(outputs.scores[1][0], dim=0)}\n",
        "The corresponding token is: {tokenizer.decode(torch.argmax(outputs.scores[1][0], dim=0))}\n",
        "\n",
        "The ID of the most probable *third* token is {torch.argmax(outputs.scores[2][0], dim=0)}\n",
        "The corresponding token is: {tokenizer.decode(torch.argmax(outputs.scores[2][0], dim=0))}\n",
        "\n",
        "This is how GPT2 gradually generated the text:\n",
        "{tokenizer.batch_decode(outputs.sequences, skip_special_tokens=True)}\n",
        "\n",
        "The same principles apply to all generative LLMs like GPT4, Llama-2 etc.\n",
        "Only that they are bigger, with a better architecture and better fine-tuning.\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dREWnBIZ5q0d",
        "outputId": "70f9fda2-0821-4043-b14d-b6c635eb9c01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "While the outputs produce by classifiers like BERT are probabilities of classes,\n",
            "the outputs produced by generators like GPT2 are probabilities of tokens.\n",
            "\n",
            "These probabilities of tokens are in the 'outputs' object returned by model.generate()\n",
            "\n",
            "The IDs of the most probably tokens are:\n",
            "tensor([[8888,  314, 1975,  356,  460, 3443,  651,  284,  262,  966,  810,  356,\n",
            "          460,  787,  257, 3580,  287,  262, 3160,  286,  262,  661,  286,  262,\n",
            "         1578, 1829,  286, 2253,   13,  198]])\n",
            "\n",
            "These token IDs can be mapped to actuall words/tokens in the vocabulary:\n",
            "['Today I believe we can finally get to the point where we can make a difference in the lives of the people of the United States of America.\\n']\n",
            "\n",
            "\n",
            "\n",
            "Our original prompt was:\n",
            "'Today I believe we can finally'\n",
            "GPT2 then tries to predict the most probable next token. One token after the other.\n",
            "\n",
            "To calculate the first token, it makes a prediction over ALL of the 50257 tokens it knows.\n",
            "Each of the 50257 tokens receives a probability.\n",
            "First the first token, the probability distribution over its ENTIRE vocabulary looks like this:  \n",
            "tensor([-148.6821, -149.2908, -156.0585,  ..., -162.4584, -158.8699,\n",
            "        -150.9391])\n",
            "      \n",
            "The ID of the most probable *first* token is 651\n",
            "The corresponding token is:  get\n",
            "      \n",
            "The ID of the most probable *second* token is 284\n",
            "The corresponding token is:  to\n",
            "\n",
            "The ID of the most probable *third* token is 262\n",
            "The corresponding token is:  the\n",
            "      \n",
            "This is how GPT2 gradually generated the text:\n",
            "['Today I believe we can finally get to the point where we can make a difference in the lives of the people of the United States of America.\\n']\n",
            "      \n",
            "The same principles apply to all generative LLMs like GPT4, Llama-2 etc.\n",
            "Only that they are bigger, with a better architecture and better fine-tuning.\n",
            "But the token-generation principle is the same. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "wjTJh6DaMsSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions"
      ],
      "metadata": {
        "id": "ja80SRkiLP50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Reading, thinking & asking:** (5 min)\n",
        "* Re-read the notebook and ask any questions you might have in the chat.\n",
        "\n",
        "* Write your answers to the following questions on a piece of paper / digital notebook. While think about these questions, also don't hesitate to ask any questions that come up in the chat.\n",
        "    * In your own words, write down the main differences between models like BERT and models like GPT with regard to their outputs.\n",
        "    * What could be disadvantages and advantages of these two different approaches (encoders vs. decoders)?\n",
        "\n",
        "* I'll collect your questions and answer them after a few minutes.\n",
        "\n"
      ],
      "metadata": {
        "id": "y8uhW4V_AU-m"
      }
    }
  ]
}